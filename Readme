# 🫀 NNX LLM - Multi-Agent PDF Processing System

> **Intelligent PDF processing powered by Gemini Vision AI**  
> Extracts text, tables, and images from multi-page PDFs using specialized AI agents.

---

##  Features

- **🤖 Multi-Agent Architecture**: Specialized agents for text, tables, and images
- **🧠 LLM-Powered**: Uses Google Gemini Vision for intelligent extraction
- **📄 Page-by-Page Processing**: Each page processed independently
- **📊 Structured Output**: Complete JSON with all extracted content
- **🚀 FastAPI Backend**: Modern, fast, auto-documented REST API
- **🔄 No Data Loss**: All agent outputs preserved in final JSON
- **⚡ Async Processing**: Fast and efficient document handling

---

## 📁 Project Structure

```
heart-llm/
├── main.py              # FastAPI server & Heart LLM orchestrator
├── text_agent.py        # Text extraction agent (Gemini Vision)
├── table_agent.py       # Table detection agent (Gemini Vision)
├── image_agent.py       # Image extraction agent (PyMuPDF)
├── config.py            # Configuration management
├── requirements.txt     # Python dependencies
├── .env                 # Environment variables (API keys)
├── README.md           # This file
└── .gitignore          # Git ignore rules
```

---

## 🚀 Quick Start

### 1. Prerequisites

- Python 3.8+
- Google Gemini API key ([Get one here](https://makersuite.google.com/app/apikey))

### 2. Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/heart-llm.git
cd heart-llm

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Configuration

Create a `.env` file in the project root:

```env
GEMINI_API_KEY=your_gemini_api_key_here
HOST=0.0.0.0
PORT=8000
GEMINI_MODEL=gemini-2.0-flash-exp
IMAGE_DPI=250
```

### 4. Run the Server

```bash
uvicorn main:app --reloa